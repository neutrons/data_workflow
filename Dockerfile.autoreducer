FROM continuumio/miniconda3

# install dependencies
COPY conda_environment.yml .
RUN conda env update --name base --file conda_environment.yml

# install postprocessing
RUN pip install https://github.com/neutrons/post_processing_agent/releases/download/v2.5/postprocessing-2.5-py3-none-any.whl

# install the fake test data
ARG DATA_TARBALL=/tmp/SNSdata.tar.gz
COPY SNSdata.tar.gz ${DATA_TARBALL}
RUN ls ${DATA_TARBALL}
RUN mkdir /SNS
RUN cd /SNS && tar xzf ${DATA_TARBALL}

# pull down the developer configuration file
RUN mkdir -p /etc/autoreduce/
RUN python -c "import requests;result=requests.get('https://raw.githubusercontent.com/neutrons/post_processing_agent/main/configuration/post_process_consumer.conf.development');open('/etc/autoreduce/post_processing.conf', 'wb').write(result.content)"

# This configuration allows it to run with docker-compose from https://github.com/neutrons/data_workflow
RUN sed -i 's/localhost/activemq/' /etc/autoreduce/post_processing.conf

# create startup script
RUN echo "#!/bin/bash" > /usr/bin/run_postprocessing && \
    echo "/opt/postprocessing/queueProcessor.py &" >> /usr/bin/run_postprocessing && \
    echo "sleep 1" >> /usr/bin/run_postprocessing && \
    echo "tail -F /opt/postprocessing/log/postprocessing.log" >> /usr/bin/run_postprocessing && \
    chmod +x /usr/bin/run_postprocessing

# start the service
CMD run_postprocessing
